syntax = "proto3";

package api;

import "google/protobuf/duration.proto";



service OpenVAService {
    rpc TTSStringToMP3 (TTSRequest) returns (TTSReply) {}
    rpc STT (stream STTRequest) returns (stream StreamingRecognizeResponse) {}
    rpc Library (LibraryFilterRequest) returns (LibraryItems) {}
    rpc HeartBeat (stream HeartBeatMessage) returns (stream HeartBeatMessage) {}
    rpc HandlerServerSideCommand(TTSRequest) returns (TTSReply) {}
    rpc HandlerServerSideCommandText(TTSRequest) returns (TTSTextReply) {}
}

message HeartBeatMessage
{
    SystemInformationMessage SystemInformation = 1;
    PlayerStateMessage PlayerState = 2;
}

message PlayerStateMessage {
    string NowPlaying = 1;
}

message SystemInformationMessage {
    string SystemUUID = 1;
    int64 UptimeSinceEpoch = 2;
    NetworkConfigurationMessage NetworkConfiguration = 3;
}

message NetworkConfigurationMessage {
    string IPAddress = 1;
    string NetMask = 2;
    string Gateway = 3;
    string DNSServers = 4;
}

message LibraryFilterRequest {
    string criteria = 1;
    int32 limit = 2;
    int32 page = 3;
}

message LibraryItem {
    string URL = 1;
    string Artist = 2;
    string Album = 3;
    string Track = 4;
    int32 Length = 5;
}


message LibraryItems {
    repeated LibraryItem items = 1;
}

message TTSRequest {
    string text = 1;
}

message TTSReply {
    bytes MP3Response = 1;
}

message TTSTextReply {
    string text = 1;
}

message STTRequest {
    bytes STTBuffer = 1;
}

message StreamingRecognizeResponse {
    // Indicates the type of speech event.
    enum SpeechEventType {
        // No speech event specified.
        SPEECH_EVENT_UNSPECIFIED = 0;

        // This event indicates that the server has detected the end of the user's
        // speech utterance and expects no additional speech. Therefore, the server
        // will not process additional audio (although it may subsequently return
        // additional results). The client should stop sending additional audio
        // data, half-close the gRPC connection, and wait for any additional results
        // until the server closes the gRPC connection. This event is only sent if
        // `single_utterance` was set to `true`, and is not used otherwise.
        END_OF_SINGLE_UTTERANCE = 1;
    }

    // Output only. If set, returns a [google.rpc.Status][google.rpc.Status]
    // message that specifies the error for the operation.
    // google.rpc.Status error = 1;

    // Output only. This repeated list contains zero or more results that
    // correspond to consecutive portions of the audio currently being processed.
    // It contains zero or one `is_final=true` result (the newly settled portion),
    // followed by zero or more `is_final=false` results (the interim results).
    repeated StreamingRecognitionResult results = 2;

    // Output only. Indicates the type of speech event.
    SpeechEventType speech_event_type = 4;
}

message StreamingRecognitionResult {
    repeated SpeechRecognitionAlternative alternatives = 1;
    bool is_final = 2;
    float stability = 3;
    //int32 channel_tag = 5;
}

message SpeechRecognitionAlternative {
    string transcript = 1;
    float confidence = 2;
    repeated WordInfo words = 3;
}


message WordInfo {
    google.protobuf.Duration start_time = 1;
    google.protobuf.Duration end_time = 2;
    string word = 3;
}
